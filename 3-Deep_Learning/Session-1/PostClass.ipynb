{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce1d1c5",
   "metadata": {},
   "source": [
    "## PostClass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc1c6fb",
   "metadata": {},
   "source": [
    "- Deep Learning:\n",
    "    1. Artificial Neural Networks (ANN)\n",
    "        - Tabular data varsa kullanılır.\n",
    "        - Çok büyük datalarda iyi çalışır.\n",
    "    2. Convulotional Neural Networks (CNN)\n",
    "        - Görüntü varsa (computer vision) kullanılır.\n",
    "    3. Recurrent Neural Networks (RNN)\n",
    "        - Geri besleme vardır.\n",
    "        \n",
    "    - Deep learning'de \"Transfer Learning\" imkanı var. Yani önceden öğrenmiş bir modele yeni şeyler öğretme imkanı var.\n",
    "    - Deep Learning, documents, images, text ve unstructured data'da başarılı olduğu için de tercih edilir.\n",
    "    \n",
    "    \n",
    "- Every neural network consists of 3 dundamental layers:\n",
    "    - **Input Layer :** Receives the information.\n",
    "    - **Hidden Layer :** Where the computations are done.\n",
    "    - **Output Layer :** Where the final results of the computations show up.\n",
    "   \n",
    "   \n",
    "- Bir katmanlı(hidden layer) Neural Networks, birden fazla katman olursa Deep Learning.\n",
    "\n",
    "\n",
    "- **Activation Functions:**\n",
    "    - Nöronların oluşturduğu değerlere(y^) düzenleme yapma işlemidir.\n",
    "    - Ayrıca neural network'e non-linearity ekleme amacı taşır.\n",
    "    \n",
    "    \n",
    "    \n",
    "- **Types of Activation Functions:** (Modern neural network models use non-linear activation functions)\n",
    "    1. Binary Step Function:\n",
    "        - Ya 0, ya da 1 üretir.\n",
    "        \n",
    "    2. Linear Activation Function:\n",
    "        - Genelde son layer'da kullanılır.\n",
    "        \n",
    "    3. Non-Linear Activation Functions:\n",
    "        - Sigmoid \n",
    "           - 0 ile 1 aralığında değer üretir.\n",
    "           - Hesaplama maliyeti var.\n",
    "           - 0.5 değerine odaklı çıktı verir.\n",
    "           - X'in çok büyük ve küçük değerleri için öğrenmeyi geciktirir.\n",
    "        - TanH / Hyperbolic Tangent ( -1 ile 1 aralığında değer üretir.)\n",
    "            - Çıktılar 0 odaklıdır.\n",
    "            - Sigmoid'den daha verimlidir.\n",
    "            - Hesaplama maliyeti bulunmaktadır.\n",
    "            - Öğrenme problemi çıkabilir.\n",
    "        - RelU (Rectified Linear Unit)\n",
    "            - Hesaplama maliyeti düşük.\n",
    "            - Non-Linear\n",
    "            - The dying ReLU problem. (önceki iki fonksiyonda vanishing problemi oluşurken burada dying problemi oluşur. Yani output 0 oluyor.\n",
    "        - Leaky ReLU\n",
    "            - Dying ReLU problemini engeller.\n",
    "        - Softmax\n",
    "            - Able to handle multiple classes.\n",
    "            - Hepsinin toplamı 1 olacak şekilde olasılıklar üretir. Hangi class'ın olasılığı yüksekse ona atama yapılır.\n",
    "            - Genelde output layer'da kullanılır.\n",
    "  \n",
    "  \n",
    "- The activation function is responsible for deciding whether a neuron should be activated or not. It makes the decision by calculating the weighted sum and further adding bias with it.\n",
    "\n",
    "\n",
    "- The basic purpose of the activation function is to introduce non-linearity into  the output of a neuron.\n",
    "\n",
    "\n",
    "- **Cost Function :**\n",
    "    - The cost function is used to predict how bad the model is performing. This is basically explained as a difference between the predicted value and the actual value.\n",
    "    - The objective of a Deep Learning model is to find the right weights and biases that minimizes the cost function. In other words, models learn by minimizing the cost function.\n",
    "    - Bizim amacımız cost function'ı minimize etmek.\n",
    "    - Burada Global minimum - Local minimum problemi ile karşılaşabiliriz. Random değerler ile modelleme yaptığımızda local minimum'a takılma durumu oluşuyor. Bundan kurtulmak için de \"learning rate\" üzerinde düzenleme yapacağız.\n",
    "    \n",
    "    \n",
    "- **Gradient Descent :**\n",
    "    - Gradient Descent is an optimization algorithm used to minimize the cost function.\n",
    "    - It is an iteration algorithm, in every iteration algorithm, we compute the gradient of a cost function, concerning each parameter and update the parameters of our model.\n",
    "    \n",
    "    \n",
    "- **Adam Optimizer :**\n",
    "    - Adam is am- method for optimization. In other words, it is one of the way to implement the Gradient Descent Algorithm.\n",
    "    - It is among the latest trends and perhaps the most efficient method.\n",
    "    \n",
    "    \n",
    "- **Backpropagation :**\n",
    "    - Going back and updating the weights and biases is called Backpropagation.\n",
    "    - Backpropagation is a training algorithm which is used for multilayer neural networks. It transfers the error information from the end of the network to all the weights inside the network. It allows the efficient computation of gradient.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdee594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31562457",
   "metadata": {},
   "source": [
    "- Dataset:\n",
    "    - Training Dataset\n",
    "    - Validation Dataset\n",
    "        - Model, öğrenme yaparken validation dataseti kullanarak training'i bitirip bitirmeyeceğine karar veriyor.\n",
    "        - Validatiın datasetini her zaman kullanmak şart değil.\n",
    "    - Test Dataset\n",
    "        - Test Dataseti, en baştan beri holdout olarak tutulur ve en son prediction için kullanılır.\n",
    "       \n",
    "\n",
    "- Training ve Validation Score'larına göre Overfitting-Underfitting problemi ortaya çıkabilir.\n",
    "\n",
    "- Deep learning'de datanın büyük olması istenir ki model iyi çalışsın.\n",
    "\n",
    "- Classification\n",
    "    1. Binary Classification:\n",
    "        - Çıkış ya 0 ya da 1 olur. Yani tek nöronlu output layer yeterlidir.\n",
    "     \n",
    "    2. Multiclass Classification:\n",
    "        - Class sayısına göre output layer'daki nöron sayısı değişir.\n",
    "        \n",
    "        A. Mutually Exclusive Classes:\n",
    "            - Genelde bunula çalışılır.\n",
    "            - Burda `softmax` activation function'ı kullanılır.\n",
    "           \n",
    "        B. Non-exclusive Classes:\n",
    "            - Sonuç 2 sınıfa da ait olabilir.\n",
    "            - Burada `sigmoid` activation function kullanılır.\n",
    "            - Hastanın hem grip olması hem de bronşit olması durumu örnek verilebilir. Yani hastada birden fazla hastalık olması durumu.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "- **----Problem Type-----------------Output Type------------------Final Activation Function------------------Loss Function**\n",
    "     - Regression-----------------> Numerical Value--------------> Linear------------------------------------------> MSE\n",
    "    \n",
    "     - Classification-------------> Binary Outcome---------------> Sigmoid-----------------------------------------> Binary Cross Entropy\n",
    "     \n",
    "     - Classification-------------> Single Label, Multiple Classes-> Softmax-------------------------------------> Cross Entropy\n",
    "     \n",
    "     - Classification------------->Multiple Labels, Multiple Classes-> Sigmoid-----------------------------------> Binary Cross Entropy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae07eddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50bf9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e44c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc50dc6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5923b65d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3008dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a1835f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236893f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf070ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33221796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23360e18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95c0279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89deb758",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
