{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d88a85d",
   "metadata": {},
   "source": [
    "## Model Deployment with SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b8988f",
   "metadata": {},
   "source": [
    "### 1. Creating a Model\n",
    "Create a model in SageMaker—By creating a model, you tell SageMaker where it can find the model components. This includes the S3 path where the model artifacts are stored and the Docker registry path for the image that contains the inference code.\n",
    "\n",
    "The following example shows how to create a model using the AWS SDK for Python (Boto3). The first few lines define:\n",
    "\n",
    "- **sagemaker_client:** A low-level SageMaker client object that makes it easy to send and receive requests to AWS services.\n",
    "\n",
    "- **sagemaker_role:** A string variable with the SageMaker IAM role Amazon Resource Name (ARN).\n",
    "\n",
    "- **aws_region:** A string variable with the name of your AWS region.\n",
    "\n",
    "**Tips-1:** The S3 bucket where the model artifacts are stored must be in the same region as the model that you are creating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59e28465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abc26e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify your AWS Region\n",
    "aws_region = \"us-east-1\"\n",
    "\n",
    "# Create a low-level SageMaker service client\n",
    "sagemaker_client = boto3.client(\"sagemaker\", region_name = aws_region)\n",
    "\n",
    "# Role to give SageMaker permission to access AWS services.\n",
    "sagemaker_role = \"arn:aws:iam:region:account:role/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f860373",
   "metadata": {},
   "source": [
    "Next, specify the location of the pre-trained model stored in Amazon S3. In this example, we use a pre-trained XGBoost model named ``demo-xgboost-model.tar.gz``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f2bd377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable with the model s3 URI\n",
    "s3_bucket = \"smworkshop-firat-olcum\" # Provide the name of your S3 bucket\n",
    "bucket_prefix = \"saved_models\"\n",
    "model_s3_key = f\"{bucket_prefix}/demo-xgboost-model.tar.gz\"\n",
    "\n",
    "# Specify S3 bucket with model\n",
    "model_url = f\"s3://{s3_bucket}/{model_s3_key}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cf05ad",
   "metadata": {},
   "source": [
    "Specify a primary container. For the primary container, you specify the Docker image that contains inference code, artifacts (from prior training), and a custom environment map that the inference code uses when you deploy the model for predictions.\n",
    "\n",
    "In this example, we specify an XGBoost built-in algorithm container image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8f65780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35285048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify an AWS container image.\n",
    "container = image_uris.retrieve(region = aws_region, framework = \"xgboost\", version = \"0.90-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab559061",
   "metadata": {},
   "source": [
    "Create a model in Amazon SageMaker with CreateModel. Specify the following:\n",
    "\n",
    "- **ModelName:** A name for your model (in this example it is stored as a string variable called model_name).\n",
    "\n",
    "- **ExecutionRoleArn:** The Amazon Resource Name (ARN) of the IAM role that Amazon SageMaker can assume to access model artifacts and Docker images for deployment on ML compute instances or for batch transform jobs.\n",
    "\n",
    "- **PrimaryContainer:** The location of the primary Docker image containing inference code, associated artifacts, and custom environment maps that the inference code uses when the model is deployed for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9869ec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"The_name_of_the_model\"\n",
    "\n",
    "# Create model\n",
    "create_model_response = sagemaker_client.create_model(Model_name = model_name,\n",
    "                                                      ExecutionRoleArn = sagemaker_role,\n",
    "                                                      PrimaryContainer = {\"Image\" : container, \"ModelDataUrl\" : model_url})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f437154",
   "metadata": {},
   "source": [
    "### 2. Creating an Endpoint Configuration\n",
    "Once you have a model, create an endpoint configuration with ``CreateEndpointConfig.`` Amazon SageMaker hosting services uses this configuration to deploy models. In the configuration, you identify one or more models, created using with ``CreateModel``, to deploy the resources that you want Amazon SageMaker to provision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "548beb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f2b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an endpoint config name. Here we can create one based on the date.\n",
    "# so it we can search endpoints based on creation time.\n",
    "endpoint_config_name = f\"XGBoostEndpointConfig-{strftime('%Y-%m-%d-%H-%M-%S', gmtime())}\"\n",
    "\n",
    "# The name of the model that you want to host. This is the name that you specified when creating the model.\n",
    "model_name = \"The_name_of_your_model\"\n",
    "\n",
    "endpoint_config_response = sagemaker_client.create_endpoint_config(\n",
    "                           EndPointConfigName = endpoint_config_name, # You will specify this name in a CreateEndpoint request.\n",
    "                           # List of ProductionVariant objects, one for each model that you want to host at this endpoint.\n",
    "                           ProductionVariants = [\n",
    "                               {\n",
    "                                   \"VariantName\" : \"variant1\", # The name of the production variant.\n",
    "                                   \"ModelName\" : model_name, # \n",
    "                                   \"InstanceType\" : \"ml.m5.xlarge\", # Specify the compute instance type.\n",
    "                                   \"InıtıalInstanceCount\" : 1 # Number of instances to launch initially.\n",
    "                               }\n",
    "                           ]\n",
    "                           \n",
    ")\n",
    "\n",
    "print(f\"Created EndpointConfig: {endpoint_config_response['EndpointConfigArn']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ab304b",
   "metadata": {},
   "source": [
    "In the aforementioned example, you specify the following keys for the ProductionVariants field:\n",
    "\n",
    "**VariantName:** The name of the production variant.\n",
    "\n",
    "**ModelName:** The name of the model that you want to host. This is the name that you specified when creating the model.\n",
    "\n",
    "**InstanceType:** The compute instance type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15f074f",
   "metadata": {},
   "source": [
    "### 3. Creating an Endpoint\n",
    "- To create an HTTPS endpoint, provide the endpoint configuration to SageMaker. The service launches the ML compute instances and deploys the model or models as specified in the configuration.\n",
    "\n",
    "- Once you have your model and endpoint configuration, use the CreateEndpoint API to create your endpoint. The endpoint name must be unique within an AWS Region in your AWS account.\n",
    "\n",
    "**Tips-1:** Endpoints are scoped to an individual AWS account, and are not public."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7556b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name of the endpoint. The name must be unique within an AWS Region in your AWS account.\n",
    "endpoint_name = \"endpoint-name\"\n",
    "\n",
    "# The name of the endpoint configuration associated with this endpoint.\n",
    "endpoint_config_name = \"endpoint_config_name\"\n",
    "\n",
    "create_endpoint_response = sagemaker_client.create_endpoint(EndpointName = endpoint_name,\n",
    "                                                            EndpointConfigName = endpoint_config_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af15c863",
   "metadata": {},
   "source": [
    "**Tips-2:** DELETE THE ENDPOINT AS SOON AS YOU ARE DONE, TO AVOID ADDITIONAL PAYMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20167a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete endpoint\n",
    "sasgemaker_client.delete_endpoint(EndpointName = endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a755732",
   "metadata": {},
   "source": [
    "### 4. Deploy Models for Inference\n",
    "After you build and train your models, you can deploy them to get predictions.\n",
    "\n",
    "To set up a persistent endpoint to get predictions from your models, use Amazon SageMaker hosting services. \n",
    "\n",
    "You can deploy the trained model across one or more load-balanced compute instances. SageMaker provides a real-time endpoint to invoke your model from client applications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
